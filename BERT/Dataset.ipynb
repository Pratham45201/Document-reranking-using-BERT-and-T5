{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "qrels_df = pd.read_csv(r\"D:\\IR\\Project\\collections\\msmarco-passage\\qrels.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"ignore\", \"doc_id\", \"relevance\"])\n",
    "\n",
    "# run.msmarco-passage.dev.small.tsv: initial BM25 ranking (query_id, document_id, rank)\n",
    "bm25_df = pd.read_csv(r\"D:\\IR\\Project\\collections\\msmarco-passage\\run.msmarco-passage.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"doc_id\", \"rank\"])\n",
    "\n",
    "# queries.dev.small.tsv: query texts\n",
    "queries_df = pd.read_csv(r\"D:\\IR\\Project\\collections\\msmarco-passage\\queries.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"query\"])\n",
    "\n",
    "# collection.tsv: document texts\n",
    "collection_df = pd.read_csv(r\"D:\\IR\\Project\\collections\\msmarco-passage\\collection.tsv\", sep=\"\\t\", header=None, names=[\"doc_id\", \"doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = bm25_df.merge(qrels_df[['query_id', 'doc_id', 'relevance']], on=['query_id', 'doc_id'], how='left')\n",
    "merged_df['relevance'] = merged_df['relevance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187158</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187157</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187163</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7546327</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id   doc_id  rank  relevance\n",
       "0   1048585  7187158     1        1.0\n",
       "1   1048585  7187157     2        0.0\n",
       "2   1048585  7187163     3        0.0\n",
       "3   1048585  7546327     4        0.0\n",
       "4   1048585  7187160     5        0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = merged_df.merge(queries_df, on='query_id').merge(collection_df, on='doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>relevance</th>\n",
       "      <th>query</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187158</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>what is paula deen's brother</td>\n",
       "      <td>Paula Deen and her brother Earl W. Bubba Hiers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187157</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what is paula deen's brother</td>\n",
       "      <td>The New York Times. U.S. | National Briefing |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187163</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what is paula deen's brother</td>\n",
       "      <td>Racial scandals aren't always bad for business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7546327</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what is paula deen's brother</td>\n",
       "      <td>What happened to Paula Deen's first husband? k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048585</td>\n",
       "      <td>7187160</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what is paula deen's brother</td>\n",
       "      <td>Paula Deen &amp; Brother Bubba Sued for Harassment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id   doc_id  rank  relevance                         query  \\\n",
       "0   1048585  7187158     1        1.0  what is paula deen's brother   \n",
       "1   1048585  7187157     2        0.0  what is paula deen's brother   \n",
       "2   1048585  7187163     3        0.0  what is paula deen's brother   \n",
       "3   1048585  7546327     4        0.0  what is paula deen's brother   \n",
       "4   1048585  7187160     5        0.0  what is paula deen's brother   \n",
       "\n",
       "                                                 doc  \n",
       "0  Paula Deen and her brother Earl W. Bubba Hiers...  \n",
       "1  The New York Times. U.S. | National Briefing |...  \n",
       "2  Racial scandals aren't always bad for business...  \n",
       "3  What happened to Paula Deen's first husband? k...  \n",
       "4  Paula Deen & Brother Bubba Sued for Harassment...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6974598, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = data_df['query'].tolist()\n",
    "documents = data_df['doc'].tolist()\n",
    "labels = data_df['relevance'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(r\"D:\\IR\\Project\\collections\\msmarco-passage\\final_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the data\n",
    "# qrels.dev.small.tsv: relevance labels (query_id, document_id, relevance)\n",
    "qrels_df = pd.read_csv(\"qrels.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"ignore\", \"doc_id\", \"relevance\"])\n",
    "\n",
    "# run.msmarco-passage.dev.small.tsv: initial BM25 ranking (query_id, document_id, rank)\n",
    "bm25_df = pd.read_csv(\"run.msmarco-passage.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"doc_id\", \"rank\"])\n",
    "\n",
    "# queries.dev.small.tsv: query texts\n",
    "queries_df = pd.read_csv(\"queries.dev.small.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"query\"])\n",
    "\n",
    "# collection.tsv: document texts\n",
    "collection_df = pd.read_csv(\"collection.tsv\", sep=\"\\t\", header=None, names=[\"doc_id\", \"doc\"])\n",
    "\n",
    "# Merge BM25 rankings with the relevance data\n",
    "merged_df = bm25_df.merge(qrels_df[['query_id', 'doc_id', 'relevance']], on=['query_id', 'doc_id'], how='left')\n",
    "merged_df['relevance'] = merged_df['relevance'].fillna(0)  # Non-relevant documents get label 0\n",
    "\n",
    "# Merge with query and document texts\n",
    "data_df = merged_df.merge(queries_df, on='query_id').merge(collection_df, on='doc_id')\n",
    "\n",
    "# Prepare data for BERT fine-tuning (query, document, and labels)\n",
    "queries = data_df['query'].tolist()\n",
    "documents = data_df['doc'].tolist()\n",
    "labels = data_df['relevance'].astype(int).tolist()\n",
    "\n",
    "# Tokenizer and model (BERT for sequence classification)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
    "\n",
    "# Create Dataset class\n",
    "class RankingDataset(Dataset):\n",
    "    def __init__(self, queries, documents, labels):\n",
    "        self.queries = queries\n",
    "        self.documents = documents\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        query = self.queries[idx]\n",
    "        document = self.documents[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer.encode_plus(query, document, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return input_ids, attention_mask, torch.tensor(label)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
    "    queries, documents, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = RankingDataset(train_queries, train_docs, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = RankingDataset(val_queries, val_docs, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "        # Evaluation after each epoch\n",
    "        evaluate_model(model, val_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    model.train()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, epochs=3)\n",
    "\n",
    "# Inference and reranking\n",
    "def rerank_documents(model, queries, documents):\n",
    "    model.eval()\n",
    "    rankings = []\n",
    "    with torch.no_grad():\n",
    "        for query, document in zip(queries, documents):\n",
    "            encoding = tokenizer.encode_plus(query, document, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            score = torch.softmax(outputs.logits, dim=1)[0][1].item()  # Get the probability of relevance (class 1)\n",
    "            rankings.append(score)\n",
    "    return rankings\n",
    "\n",
    "# Use rerank_documents to rerank the BM25 results\n",
    "query_ids = data_df['query_id'].tolist()\n",
    "doc_ids = data_df['doc_id'].tolist()\n",
    "reranked_scores = rerank_documents(model, queries, documents)\n",
    "\n",
    "# Combine the results into a DataFrame and sort by score for each query\n",
    "results_df = pd.DataFrame({'query_id': query_ids, 'doc_id': doc_ids, 'score': reranked_scores})\n",
    "results_df = results_df.sort_values(by=['query_id', 'score'], ascending=[True, False])\n",
    "\n",
    "# Save the reranked results\n",
    "results_df.to_csv(\"reranked_results.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
